{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from data_loader import FERDataset\n",
    "import transform\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "print('Torch version: {}'.format(torch.__version__))\n",
    "print('Torchvision version: {}'.format(torchvision.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('GPU: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transform.Normalize(),\n",
    "    transform.ToTensor()\n",
    "])\n",
    "\n",
    "train = FERDataset('fer2013.csv', 'Training', transform=data_transforms)\n",
    "val = FERDataset('fer2013.csv', 'PublicTest', transform=data_transforms)\n",
    "# test = FERDataset('fer2013.csv', 'PrivateTest', transform=data_transforms)\n",
    "print(len(train), len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "train_loader = DataLoader(train, batch_size=bs, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral')\n",
    "num_samples = 4\n",
    "for idx, sample in enumerate(train_loader):\n",
    "    if idx == num_samples:\n",
    "        break\n",
    "    images, labels = sample['image'], sample['label']\n",
    "    image = torch.squeeze(images[0]) * 255\n",
    "    plt.subplot(1, num_samples, idx+1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(classes[int(labels[0].numpy())])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmoNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(EmoNet, self).__init__()\n",
    "        self.reset()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128*3*3, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(200, 7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        n_feats = 1\n",
    "        for s in x.size()[1:]:\n",
    "            n_feats *= s\n",
    "\n",
    "        return n_feats\n",
    "    \n",
    "    def reset(self):\n",
    "        self.train_loss_history = []\n",
    "        self.train_acc_history = []\n",
    "        self.val_loss_history = []\n",
    "        self.val_acc_history = []\n",
    "\n",
    "    def print_params(self):\n",
    "        total_params = sum(param.numel() for param in self.parameters())\n",
    "        trainable = sum(param.numel() for param in self.parameters() if param.requires_grad == True)\n",
    "        print('Total params: {}\\nTrainable params: {}'.format(total_params, trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmoNet()\n",
    "print(model)\n",
    "model.print_params()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(model, train_loader, val_loader, use_cuda, print_every, n_epochs):\n",
    "    print('\\nStarted training...\\n')\n",
    "    best_val_acc = 0.50\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train\n",
    "        running_train_loss = 0.0\n",
    "        for batch, sample in enumerate(train_loader):\n",
    "            images, labels = sample['image'], sample['label']\n",
    "            if use_cuda:\n",
    "                images = images.to(device, dtype=torch.float)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            train_loss = criterion(output, labels.squeeze(1))\n",
    "            running_train_loss += train_loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (batch+1) % print_every == 0:\n",
    "                print('[Iteration {}/{}] Training loss: {:.3f}'.format(batch+1, len(train_loader), train_loss.item()))\n",
    "        model.train_loss_history.append(running_train_loss/len(train_loader))\n",
    "        with torch.no_grad():\n",
    "            model.eval\n",
    "            running_val_loss = 0.0\n",
    "            val_acc = 0.0\n",
    "            for batch, sample in enumerate(val_loader):\n",
    "                image_val, label_val = sample['image'], sample['label']\n",
    "                if use_cuda:\n",
    "                    image_val = image_val.to(device, dtype=torch.float)\n",
    "                    label_val = label_val.to(device)\n",
    "                    \n",
    "                o_val = model(image_val)\n",
    "                val_loss = criterion(o_val, label_val.squeeze(1))\n",
    "                running_val_loss += val_loss.item()\n",
    "                \n",
    "                total = label_val.size(0)\n",
    "                _, prediction = torch.max(o_val.data, 1)\n",
    "                correct = (prediction == label_val.squeeze(1)).sum().item()\n",
    "                val_acc += (correct/total)\n",
    "                \n",
    "            model.val_loss_history.append(running_val_loss/len(val_loader))\n",
    "            model.val_acc_history.append(val_acc/len(val_loader))\n",
    "        print('[Epoch {}/{}] Training loss: {:.3f}, Validation loss: {:.3f}, Validation acc: {:.3f}\\n'.format(epoch+1, n_epochs, model.train_loss_history[-1], model.val_loss_history[-1], model.val_acc_history[-1]))\n",
    "        \n",
    "        if model.val_acc_history[-1] >= best_val_acc:\n",
    "            best_val_acc = model.val_acc_history[-1]\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            print('Achieved better validation acc. Saving state...')\n",
    "    print('\\nFinished training...\\n')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-6)\n",
    "best_model = train_net(model, train_loader, val_loader, True, 200, 10)\n",
    "torch.save(best_model, 'Saved_Models/model1.pt')\n",
    "time_elapsed = time.time() - since\n",
    "print('Total training time: {}m {}s'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.train_loss_history)\n",
    "plt.plot(model.val_loss_history)\n",
    "plt.legend(['train', 'val'])\n",
    "plt.title('Training vs. Validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv.CascadeClassifier('/home/hashir/anaconda3/lib/python3.7/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "saved_model = torch.load('Saved_Models/model1.pt')\n",
    "saved_model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral')\n",
    "cap = cv.VideoCapture(0)\n",
    "time.sleep(2.0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        face_gray = gray[y:y+h, x:x+w]\n",
    "        sample = cv.resize(face_gray, (48, 48))\n",
    "        sample = sample.astype('float32')/255.\n",
    "        sample = np.asarray(sample).reshape(1,48,48)\n",
    "        sample = torch.from_numpy(sample).unsqueeze(0).to(device)\n",
    "        output = saved_model(sample)\n",
    "        _, prediction = torch.max(output.data, 1)\n",
    "        label = classes[prediction]\n",
    "        cv.putText(frame, str(label), (x-10, y-20), cv.FONT_HERSHEY_SIMPLEX, 1.2, (0,0,255), 1, cv.LINE_AA)\n",
    "    cv.imshow(\"Frame\", frame)\n",
    "    key = cv.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
